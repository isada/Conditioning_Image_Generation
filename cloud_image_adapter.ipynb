{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbbbbbbbbb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This code orchestrates the environment setup for a ComfyUI project,\n",
        "allowing users to customize preferences, install dependencies, and integrate with Google Drive,\n",
        "while also cloning, updating, and configuring necessary components\n",
        "like ComfyUI-Manager, ComfyUI_IPAdapter_plus, and Control Net preprocessors.\n",
        "\"\"\"\n",
        "#@title Environment Setup: execution\n",
        "%cd /content\n",
        "from pathlib import Path\n",
        "\n",
        "# -- environment variables based on user input\n",
        "OPTIONS = {}\n",
        "\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "INSTALL_COMFYUI_MANAGER = True #@param {type:\"boolean\"}\n",
        "INSTALL_COMFYUI_IPADAPTER_PLUS = True #@param {type:\"boolean\"}\n",
        "INSTALL_CONTROLNET_PREPROCESSORS = True #@param {type:\"boolean\"}\n",
        "#@markdown <br>\n",
        "#@markdown NOTE: flag this below if you want to interact with the directories on google drive (useful if you want to avoid writing shell commands and simply drag and drop the downloaded models into the relevant folder)\n",
        "USE_GOOGLE_DRIVE = False  #@param {type:\"boolean\"}\n",
        "\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "OPTIONS['INSTALL_COMFYUI_MANAGER'] = INSTALL_COMFYUI_MANAGER\n",
        "OPTIONS['INSTALL_COMFYUI_IPADAPTER_PLUS'] = INSTALL_COMFYUI_IPADAPTER_PLUS\n",
        "OPTIONS['INSTALL_CONTROLNET_PREPROCESSORS'] = INSTALL_CONTROLNET_PREPROCESSORS\n",
        "\n",
        "# -- defining directories\n",
        "current_dir = !pwd\n",
        "IMAGE_WORKSPACE = f\"{current_dir[0]}/ImageProject\" #area where I store the project\n",
        "COMFY_WORKSPACE = f\"{current_dir[0]}/ImageProject/ComfyUI\" #sub folder with ComfyUI\n",
        "\n",
        "# -- mounting google drive if the option is selected\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    IMAGE_WORKSPACE = \"/content/drive/MyDrive/ImageProject\"\n",
        "    COMFY_WORKSPACE = \"/content/drive/MyDrive/ImageProject/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "# -- creating the workspace directory and cloning ComfyUI repo\n",
        "import os\n",
        "!echo \"Creating workspace if not already there\"\n",
        "os.makedirs(IMAGE_WORKSPACE, exist_ok=True)\n",
        "%cd $IMAGE_WORKSPACE\n",
        "\n",
        "![ ! -d $COMFY_WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $COMFY_WORKSPACE\n",
        "\n",
        "# -- updating if needed\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "  !git pull\n",
        "\n",
        "# -- installing dependencies\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "# -- installing ComfyUI-Manager\n",
        "%cd $COMFY_WORKSPACE\n",
        "if OPTIONS['INSTALL_COMFYUI_MANAGER']:\n",
        "  %cd custom_nodes\n",
        "  ![ ! -d ComfyUI-Manager ] && echo -= Initial setup ComfyUI-Manager =- && git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
        "  %cd ComfyUI-Manager\n",
        "  !git pull\n",
        "\n",
        "%cd $COMFY_WORKSPACE\n",
        "# -- installing ComfyUI_IPAdapter_plus (ComfyUI reference implementation for IPAdapter models)\n",
        "# documentation for this custom node: https://github.com/cubiq/ComfyUI_IPAdapter_plus\n",
        "\n",
        "if OPTIONS['INSTALL_COMFYUI_IPADAPTER_PLUS']:\n",
        "  %cd custom_nodes\n",
        "  ![ ! -d ComfyUI_IPAdapter_plus ] && echo -= Initial setup ComfyUI_IPAdapter_plus =- && git clone https://github.com/cubiq/ComfyUI_IPAdapter_plus\n",
        "  %cd ComfyUI_IPAdapter_plus\n",
        "  !git pull\n",
        "  #create folder for ipadapter models where the models will be saved later\n",
        "  %mkdir -p $COMFY_WORKSPACE/models/ipadapter\n",
        "\n",
        "\n",
        "%cd $COMFY_WORKSPACE\n",
        "\n",
        "# -- installing Control Net preprocessors\n",
        "\n",
        "if OPTIONS['INSTALL_CONTROLNET_PREPROCESSORS']:\n",
        "  %cd custom_nodes\n",
        "  ![ ! -d comfyUI_controlnet_aux ] && echo -= Initial setup ComfyUI_controlnet_aux =- && git clone https://github.com/Fannovel16/comfyui_controlnet_aux\n",
        "  %cd comfyui_controlnet_aux\n",
        "  !git pull\n",
        "\n",
        "\n",
        "%cd $COMFY_WORKSPACE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Environment configuration: execution\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "#@markdown **Models**\n",
        "# -- STABLE DIFFUSION: First you need the checkpoint for the stable diffusion model\n",
        "STABLE_DIFFUSION_URL = \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\"\n",
        "#STABLE_DIFFUSION_URL = \"https://civitai.com/api/download/models/128713?type=Model&format=SafeTensor&size=pruned&fp=fp16\" #@param {type:\"string\"}\n",
        "OPTIONS['STABLE_DIFFUSION_MODEL'] = STABLE_DIFFUSION_URL\n",
        "if STABLE_DIFFUSION_URL:\n",
        "  !wget -c \"{STABLE_DIFFUSION_URL}\" --content-disposition -P {COMFY_WORKSPACE}/models/checkpoints/\n",
        "\n",
        "\n",
        "#@markdown **VAE**\n",
        "# -- VAE (Variational autoencoders)\n",
        "VAE_URL = \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\" #@param {type:\"string\"}\n",
        "OPTIONS['VAE_MODEL'] = VAE_URL\n",
        "if VAE_URL:\n",
        "  !wget -c \"{VAE_URL}\" -P {COMFY_WORKSPACE}/models/vae/\n",
        "\n",
        "\n",
        "#@markdown **CONTROLNETS**\n",
        "# -- CONTROLNET: then you need the checkpoints for the CONTROLNET\n",
        "# - controlnet has models targeted toward specific tasks and I want specifically the open pose one\n",
        "download_all_control_nets = True  #@param {type:\"boolean\"}\n",
        "OPTIONS['SD_1_5_CONTROLNETS'] = download_all_control_nets\n",
        "if OPTIONS['SD_1_5_CONTROLNETS']:\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "    !wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P {COMFY_WORKSPACE}/models/controlnet/\n",
        "\n",
        "\n",
        "#@markdown **CLIP VISION**\n",
        "# -- CLIP VISION:\n",
        "# clip visions are the image encoders that are needed to work with the IP Adapter models\n",
        "CLIPVISION_URL = \"https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/model.safetensors\" #@param {type:\"string\"}\n",
        "OPTIONS['CLIPVISION_MODEL'] = CLIPVISION_URL\n",
        "\n",
        "if CLIPVISION_URL:\n",
        "    !wget -c \"{CLIPVISION_URL}\" -P {COMFY_WORKSPACE}/models/clip_vision/\n",
        "\n",
        "\n",
        "\n",
        "# all possible IP Adapter ControlNet files here https://huggingface.co/h94/IP-Adapter/tree/main/models\n",
        "#@markdown **IP ADAPTER (face)**\n",
        "IPADAPTER_FACE_URL = \"https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-plus-face_sd15.safetensors\" #@param {type:\"string\"}\n",
        "OPTIONS['IPADAPTER_FACE_MODEL']= IPADAPTER_FACE_URL\n",
        "if IPADAPTER_FACE_URL:\n",
        "    !wget -c \"{IPADAPTER_FACE_URL}\" -P {COMFY_WORKSPACE}/models/ipadapter/\n",
        "\n",
        "#@markdown **IP ADAPTER (style)**\n",
        "IPADAPTER_STYLE_URL = \"https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15.safetensors\" #@param {type:\"string\"}\n",
        "OPTIONS['IPADAPTER_STYLE_MODEL']= IPADAPTER_STYLE_URL\n",
        "\n",
        "if IPADAPTER_STYLE_URL:\n",
        "    !wget -c \"{IPADAPTER_STYLE_URL}\" -P {COMFY_WORKSPACE}/models/ipadapter/\n"
      ],
      "metadata": {
        "id": "on2s4d42jrnq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are struggling to understand the directory structure or want to check if a model has been actually installed and has been correctly placed, use the code below for displaying the content of the directories."
      ],
      "metadata": {
        "id": "PtivZXGFzN0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for example (see that by default the ComfyUI repo contains instructions about where to place the elements)\n",
        "%ls /content/ImageProject/ComfyUI/models/clip_vision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eskZDE-Wbci8",
        "outputId": "d468cbbc-6104-4671-92eb-9468a0d3d1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.safetensors  put_clip_vision_models_here\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download custom resources\n",
        "\n",
        "These resources are the ones that are needed to run my example workflow but below you have a more user friendly way to personalize the models that are added to your ComfyUI configuration.\n",
        "\n",
        "Feel free to customize it to accomodate your own personalization need.\n",
        "\n",
        "\n",
        "Note: depending on the resource you want to download select the proper folder in which you will save it. For example:\n",
        "* if you are downloading another checkpoint for stable diffusion then save it in checkpoints\n",
        "* if you are downloading another controlnet model then save it in controlnet\n",
        "* if it's an IPAdapter model then it goes directly into that folder but make sure you have it installed (ie. have executed the first node with the flag checked for comfyui ipadapter plus)\n",
        "\n"
      ],
      "metadata": {
        "id": "wCc6m-ZSgjDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Add you own resource\n",
        "#@markdown Specify file name and extension for the resource:\n",
        "resource_url = \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/coadapter-style-sd15v1.pth\" #@param {type:\"string\"}\n",
        "output_path = \"./models/ipadapter/\" #@param [\"./models/checkpoints/\",\"./models/clip_vision/\",\"./models/vae/\",\"./models/loras/\",\"./models/controlnet/\",\"./models/style_models/\", \"./models/ipadapter/\"]\n",
        "\n",
        "# considering the ComfyUI folder as starting point\n",
        "if resource_url and output_path:\n",
        "    !wget -c \"{resource_url}\" -P \"{output_path}\""
      ],
      "metadata": {
        "id": "Lx6RB2_2hDrK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkkk"
      },
      "source": [
        "## Run ComfyUI with cloudflared\n",
        "\n",
        "Once everything is setup, here 'cloudflared' gets downloaded and installed. This is a tool provided by Cloudflare, to create a secure tunnel for the ComfyUI server.\n",
        "\n",
        "The code launches the server using Python, prints the URL for accessing ComfyUI and runs the server in the background for a more smooth user experience.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#these are all modules that were missing so were pip installed on the way, if you are experiencing a \"no xyz found\" error try pip installing it first (and then relaunch this cloudflared section)\n",
        "#!pip install insightface\n",
        "#!pip install onnxruntime\n",
        "#!pip install yacs"
      ],
      "metadata": {
        "id": "Gf_SmAfp42FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb53c5b-41f7-404d-e66a-8977b4e428c4",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-12 00:06:14--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2024.2.0/cloudflared-linux-amd64.deb [following]\n",
            "--2024-02-12 00:06:14--  https://github.com/cloudflare/cloudflared/releases/download/2024.2.0/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/6cb1326e-a188-4db6-9cdb-22f9962bc7cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240212T000614Z&X-Amz-Expires=300&X-Amz-Signature=e754a7ddeea57de412e412314d5411fc260859e2632a402d8967709fd56fb135&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-02-12 00:06:14--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/6cb1326e-a188-4db6-9cdb-22f9962bc7cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240212T000614Z&X-Amz-Expires=300&X-Amz-Signature=e754a7ddeea57de412e412314d5411fc260859e2632a402d8967709fd56fb135&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17777596 (17M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64.deb.4’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  16.95M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-02-12 00:06:14 (201 MB/s) - ‘cloudflared-linux-amd64.deb.4’ saved [17777596/17777596]\n",
            "\n",
            "(Reading database ... 121761 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2024.2.0) over (2024.2.0) ...\n",
            "Setting up cloudflared (2024.2.0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "** ComfyUI startup time: 2024-02-12 00:06:15.847360\n",
            "** Platform: Linux\n",
            "** Python version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** Log path: /content/ImageProject/ComfyUI/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.0 seconds: /content/ImageProject/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "Total VRAM 15102 MB, total RAM 12979 MB\n",
            "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.2.0+cu118 with CUDA 1108 (you have 2.2.0+cu121)\n",
            "    Python  3.10.13 (you have 3.10.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "xformers version: 0.0.24+cu118\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/ImageProject/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "/content/ImageProject/ComfyUI/custom_nodes/comfyui_controlnet_aux/node_wrappers/dwpose.py:26: UserWarning: DWPose: Onnxruntime not found or doesn't come with acceleration providers, switch to OpenCV with CPU device. DWPose might run very slowly\n",
            "  warnings.warn(\"DWPose: Onnxruntime not found or doesn't come with acceleration providers, switch to OpenCV with CPU device. DWPose might run very slowly\")\n",
            "### Loading: ComfyUI-Manager (V2.7.2)\n",
            "### ComfyUI Revision: 1969 [02409c30] | Released on '2024-02-12'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ImageProject/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\n",
            "   0.1 seconds: /content/ImageProject/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "   1.5 seconds: /content/ImageProject/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "\n",
            "ComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\n",
            "\n",
            "This is the URL to access ComfyUI: https://cards-same-cambridge-pure.trycloudflare.com                                       |\n",
            "FETCH DATA from: /content/ImageProject/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json\n",
            "got prompt\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /content/ImageProject/ComfyUI/models/insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /content/ImageProject/ComfyUI/models/insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /content/ImageProject/ComfyUI/models/insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /content/ImageProject/ComfyUI/models/insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /content/ImageProject/ComfyUI/models/insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "Global Step: 840000\n",
            "model_type EPS\n",
            "adm 0\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "missing {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['betas', 'alphas_cumprod', 'alphas_cumprod_prev', 'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod', 'log_one_minus_alphas_cumprod', 'sqrt_recip_alphas_cumprod', 'sqrt_recipm1_alphas_cumprod', 'posterior_variance', 'posterior_log_variance_clipped', 'posterior_mean_coef1', 'posterior_mean_coef2', 'model_ema.decay', 'model_ema.num_updates', 'cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load BaseModel\n",
            "Loading 1 new model\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load CLIPVisionModelProjection\n",
            "Loading 1 new model\n",
            "Requested to load SD1ClipModel\n",
            "Loading 1 new model\n",
            "[] []\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 3\n",
            "100% 25/25 [00:05<00:00,  4.39it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "2024-02-12 00:10:01.430999: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-12 00:10:01.431153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-12 00:10:01.546019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-124' coro=<RequestHandler.start() done, defined at /usr/local/lib/python3.10/dist-packages/aiohttp/web_protocol.py:481> exception=AssertionError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/aiohttp/web_protocol.py\", line 524, in start\n",
            "    request = self._request_factory(message, payload, self, writer, handler)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/aiohttp/web_app.py\", line 485, in _make_request\n",
            "    return _cls(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/aiohttp/web_request.py\", line 825, in __init__\n",
            "    super().__init__(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/aiohttp/web_request.py\", line 195, in __init__\n",
            "    assert transport is not None\n",
            "AssertionError\n",
            "2024-02-12 00:10:04.214574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "set os.environ[OMP_NUM_THREADS] to 4\n",
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n",
            "=> loading pretrained model /content/ImageProject/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/ControlNet-HandRefiner-pruned/hrnetv2_w64_imagenet_pretrained.pth\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1707696619.445959  153898 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "/usr/local/lib/python3.10/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "[] []\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 2\n",
            "100% 25/25 [00:04<00:00,  5.23it/s]\n",
            "Prompt executed in 118.35 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load BaseModel\n",
            "Loading 1 new model\n",
            "unload clone 4\n",
            "100% 25/25 [00:05<00:00,  4.89it/s]\n",
            "set os.environ[OMP_NUM_THREADS] to 4\n",
            "=> loading pretrained model /content/ImageProject/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/ControlNet-HandRefiner-pruned/hrnetv2_w64_imagenet_pretrained.pth\n",
            "I0000 00:00:1707696694.395473  153898 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 1\n",
            "100% 25/25 [00:04<00:00,  5.28it/s]\n",
            "Prompt executed in 33.79 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 4\n",
            "100% 25/25 [00:05<00:00,  4.89it/s]\n",
            "set os.environ[OMP_NUM_THREADS] to 4\n",
            "=> loading pretrained model /content/ImageProject/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/ControlNet-HandRefiner-pruned/hrnetv2_w64_imagenet_pretrained.pth\n",
            "I0000 00:00:1707696798.258100  153898 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 2\n",
            "100% 25/25 [00:04<00:00,  5.29it/s]\n",
            "Prompt executed in 23.21 seconds\n",
            "got prompt\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 2\n",
            "100% 25/25 [00:05<00:00,  4.87it/s]\n",
            "set os.environ[OMP_NUM_THREADS] to 4\n",
            "=> loading pretrained model /content/ImageProject/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/ControlNet-HandRefiner-pruned/hrnetv2_w64_imagenet_pretrained.pth\n",
            "I0000 00:00:1707696837.135744  153898 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 2\n",
            "100% 25/25 [00:04<00:00,  5.27it/s]\n",
            "Prompt executed in 21.25 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load BaseModel\n",
            "Loading 1 new model\n",
            "unload clone 3\n",
            "100% 25/25 [00:05<00:00,  4.96it/s]\n",
            "set os.environ[OMP_NUM_THREADS] to 4\n",
            "=> loading pretrained model /content/ImageProject/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/ControlNet-HandRefiner-pruned/hrnetv2_w64_imagenet_pretrained.pth\n",
            "I0000 00:00:1707696861.426903  153898 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 1\n",
            "100% 25/25 [00:04<00:00,  5.24it/s]\n",
            "Prompt executed in 22.25 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 3\n",
            "100% 25/25 [00:05<00:00,  4.91it/s]\n",
            "set os.environ[OMP_NUM_THREADS] to 4\n",
            "=> loading pretrained model /content/ImageProject/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/ControlNet-HandRefiner-pruned/hrnetv2_w64_imagenet_pretrained.pth\n",
            "I0000 00:00:1707696894.108376  153898 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 2\n",
            "100% 25/25 [00:04<00:00,  5.26it/s]\n",
            "Prompt executed in 24.81 seconds\n",
            "got prompt\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 4\n",
            "100% 25/25 [00:05<00:00,  4.89it/s]\n",
            "set os.environ[OMP_NUM_THREADS] to 4\n",
            "=> loading pretrained model /content/ImageProject/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/ControlNet-HandRefiner-pruned/hrnetv2_w64_imagenet_pretrained.pth\n",
            "I0000 00:00:1707696953.856409  153898 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\n",
            "Requested to load BaseModel\n",
            "Requested to load ControlNet\n",
            "Loading 2 new models\n",
            "unload clone 2\n",
            "100% 25/25 [00:04<00:00,  5.25it/s]\n",
            "Prompt executed in 22.39 seconds\n",
            "FETCH DATA from: /content/ImageProject/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json\n"
          ]
        }
      ],
      "source": [
        "#@title Launching ComfyUI\n",
        "#@markdown Run the code then copy paste the URL for ComfyUI in the browser\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have the environment running, open the server and enjoy creating workflows. You can find my workflow here but there are also other examples of workflows here, simply download the json and load it through the comfyui manager load option.\n"
      ],
      "metadata": {
        "id": "VXzGyI5Qvz3d"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}